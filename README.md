# RCAN
[Image Super-Resolution Using Very Deep Residual Channel Attention Networks](https://arxiv.org/abs/1807.02758)

[论文源码地址](https://github.com/yulunzhang/RCAN)

本 repository 复现 RCAN，并修改 RCAN 的模型结构，使之能够在训练和推断时绕过连续的 res groups，建立每个 res group 到最后层的旁路。在训练时以 50% 的概率遍历所有层（用于训练原始路径），以 50% 的概率在剩余的旁路中随机均匀地选择一条。在测试时可以只使用模型的一部分来进行推断，并随着使用的 res group 的增加，图像质量的增益增加。

## 模型结构
每个模型的 body 由多个 residual groups 构成，每个 residual group 结构一样，由多个 residual channel attention blocks 构成。

![模型结构](https://github.com/yulunzhang/RCAN/raw/master/Figs/RCAN.PNG)

## 参数

- residual group：10
- residual channel attention block：20
- patch_size：48 * 48
- batch size：16
- iteration：1000，每个 epoch 的迭代次数
- epoch：300
- lr：1e-4
- lr_decay：200，lr 每 2*10^5 个 iteration（即 200 个 epoch）减一半
- optimizer：ADAM (gamma=0.5, beta=[0.9, 0.999], epsilon=1e-8, weight_decay=0)
- loss：L1

## 数据集

### 训练数据集
- DIV2K：1-800 张图片，低分辨率图片由高分辨率图片通过 Bicubic 下采样生成
- scale：2, 3, 4
- 数据增强：旋转，上下翻转，左右翻转
- 划分 patch：训练时每张图片随机 crop 一个 patch
- 验证集：取训练集中 10 张图片，每 1 轮验证一次，并计算在每一个 residual group 跳出的增益，即 PSNR

### 测试数据集

- DIV2K（valid）：100 张图片
- B100：100 张图片
- Set5：5 张图片
- Set14：14 张图片
- Urban100：100 张图片

## 评估指标

### PSNR
- 基础方法（Bicubic, Bilinear）

 | 基础方法 | DIV2K x 2 | DIV2K x 3 | DIV2K x 4 | Set5 x 2 | Set5 x 3 | Set5 x 4 | Set14 x 2 | Set14 x 3 | Set14 x 4 | B100 x 2 | B100 x 3 | B100 x 4 | Urban100 x 2 | Urban100 x 3 | Urban100 x 4 | 
 | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | 
 | bicubic | 31.545 | 27.062 | 25.485 | 32.073 | 28.877 | 26.916 | 28.747 | 26.102 | 24.588 | 28.323 | 25.905 | 24.63 | 25.605 | 23.117 | 21.771 | 
 | bilinear | 30.763 | 27.218 | 25.729 | 30.417 | 27.81 | 25.858 | 27.508 | 25.386 | 23.901 | 27.271 | 25.371 | 24.12 | 24.502 | 22.532 | 21.216 | 

- RCAN（全部训练）仅最后一个 res group 退出,训练 300 次

 | res group数量 | DIV2K x 2 | DIV2K x 3 | DIV2K x 4 | Set5 x 2 | Set5 x 3 | Set5 x 4 | Set14 x 2 | Set14 x 3 | Set14 x 4 | B100 x 2 | B100 x 3 | B100 x 4 | Urban100 x 2 | Urban100 x 3 | Urban100 x 4 | 
 | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | 
 | 0 | 30.7602 | 27.2038 | 25.5691 | 31.4438 | 27.5099 | 25.5273 | 28.3497 | 25.2508 | 23.7387 | 27.9968 | 25.289 | 23.981 | 25.2752 | 22.5379 | 21.176 | 
 | 1 | 30.8382 | 27.63 | 26.0896 | 31.542 | 27.821 | 25.8792 | 28.3783 | 25.3904 | 23.9217 | 28.017 | 25.3796 | 24.1481 | 25.2901 | 22.5683 | 21.2623 | 
 | 2 | 30.9369 | 27.6738 | 26.095 | 31.6845 | 27.8882 | 25.9013 | 28.473 | 25.4317 | 23.9358 | 28.1045 | 25.4107 | 24.1523 | 25.3811 | 22.6115 | 21.2745 | 
 | 3 | 31.0256 | 27.7157 | 26.1401 | 31.8031 | 27.9353 | 25.9715 | 28.5448 | 25.4769 | 23.9789 | 28.1654 | 25.4238 | 24.1842 | 25.4745 | 22.6385 | 21.299 | 
 | 4 | 31.1485 | 27.8521 | 26.2669 | 31.9433 | 28.1106 | 26.1563 | 28.6473 | 25.6214 | 24.0982 | 28.2611 | 25.5155 | 24.2735 | 25.6019 | 22.7573 | 21.3882 | 
 | 5 | 31.2612 | 27.9225 | 26.3603 | 32.0549 | 28.2113 | 26.276 | 28.7316 | 25.7138 | 24.1747 | 28.3092 | 25.5502 | 24.3319 | 25.7043 | 22.8547 | 21.4872 | 
 | 6 | 31.3987 | 28.0541 | 26.4673 | 32.2079 | 28.4403 | 26.4637 | 28.8582 | 25.8458 | 24.2842 | 28.4191 | 25.6402 | 24.4151 | 25.8665 | 22.9872 | 21.581 | 
 | 7 | 31.5885 | 28.268 | 26.5326 | 32.4622 | 28.7405 | 26.5913 | 29.0528 | 26.055 | 24.3773 | 28.5982 | 25.7991 | 24.4428 | 26.0891 | 23.1989 | 21.676 | 
 | 8 | 31.8657 | 28.5652 | 26.967 | 32.7661 | 29.1804 | 27.246 | 29.2897 | 26.3432 | 24.7991 | 28.8251 | 26.0504 | 24.77 | 26.4063 | 23.4642 | 22.0352 | 
 | 9 | 32.1619 | 28.9162 | 27.1853 | 33.1317 | 29.7058 | 27.6024 | 29.5454 | 26.677 | 25.0124 | 29.0464 | 26.2985 | 24.9169 | 26.7651 | 23.8092 | 22.2297 | 
 | 10 | 32.2571 | 28.9986 | 27.2402 | 33.2445 | 29.8464 | 27.692 | 29.663 | 26.7729 | 25.0938 | 29.0818 | 26.3247 | 24.9272 | 26.9645 | 23.9044 | 22.3098 | 

- RCAN（分层训练），50% 概率从第 0-9 个 res group 退出，50% 概率跑完 10 个 res group 退出，训练 300 次

 | res group数量 | DIV2K x 2 | DIV2K x 3 | DIV2K x 4 | Set5 x 2 | Set5 x 3 | Set5 x 4 | Set14 x 2 | Set14 x 3 | Set14 x 4 | B100 x 2 | B100 x 3 | B100 x 4 | Urban100 x 2 | Urban100 x 3 | Urban100 x 4 | 
 | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | 
 | 0 | 31.0285 | 27.8223 | 26.2707 | 31.7875 | 28.084 | 26.1361 | 28.5492 | 25.5688 | 24.0921 | 28.1635 | 25.5051 | 24.2682 | 25.432 | 22.6815 | 21.3769 | 
 | 1 | 31.9996 | 28.6184 | 26.9668 | 32.9986 | 29.3109 | 27.2977 | 29.447 | 26.3943 | 24.8349 | 28.8508 | 26.03 | 24.7258 | 26.7241 | 23.5866 | 22.1033 | 
 | 2 | 32.1469 | 28.8284 | 27.0762 | 33.1761 | 29.5714 | 27.4469 | 29.5648 | 26.5847 | 24.9515 | 29.0027 | 26.2059 | 24.8201 | 26.8626 | 23.7367 | 22.1903 | 
 | 3 | 32.1777 | 28.9002 | 27.1695 | 33.1864 | 29.681 | 27.5757 | 29.5818 | 26.6585 | 25.0443 | 29.0177 | 26.2591 | 24.8833 | 26.8903 | 23.8147 | 22.2677 | 
 | 4 | 32.1866 | 28.9569 | 27.1943 | 33.1843 | 29.7687 | 27.6305 | 29.6019 | 26.7109 | 25.0788 | 29.0237 | 26.2992 | 24.9015 | 26.9174 | 23.8608 | 22.2896 | 
 | 5 | 32.2038 | 28.9641 | 27.216 | 33.2002 | 29.7642 | 27.653 | 29.6138 | 26.7149 | 25.0955 | 29.0312 | 26.2988 | 24.9162 | 26.9374 | 23.8697 | 22.3083 | 
 | 6 | 32.2131 | 28.9932 | 27.2314 | 33.2045 | 29.7931 | 27.6812 | 29.6215 | 26.7409 | 25.1187 | 29.0273 | 26.3202 | 24.9257 | 26.9414 | 23.8889 | 22.3192 | 
 | 7 | 32.2112 | 28.9954 | 27.243 | 33.2012 | 29.797 | 27.7029 | 29.6212 | 26.7474 | 25.1303 | 29.0203 | 26.3179 | 24.931 | 26.9376 | 23.8987 | 22.3335 | 
 | 8 | 32.2021 | 28.9976 | 27.2415 | 33.191 | 29.7992 | 27.6959 | 29.6092 | 26.7486 | 25.1294 | 29.0053 | 26.3201 | 24.9297 | 26.9281 | 23.9 | 22.3329 | 
 | 9 | 32.2024 | 28.9975 | 27.2413 | 33.1936 | 29.7993 | 27.6955 | 29.6105 | 26.7488 | 25.1295 | 29.0047 | 26.32 | 24.9296 | 26.9278 | 23.8999 | 22.3328 | 
 | 10 | 32.2023 | 28.9975 | 27.2413 | 33.1934 | 29.7993 | 27.6955 | 29.6104 | 26.7488 | 25.1294 | 29.0046 | 26.32 | 24.9296 | 26.9277 | 23.8999 | 22.3327 | 

- time
